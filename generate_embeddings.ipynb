{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tiktoken\n",
    "from code_library import queries, functions\n",
    "from utils.embeddings_utils import get_embedding\n",
    "\n",
    "# embedding model parameters\n",
    "embedding_model = \"text-embedding-ada-002\" # this is the latest model (V2)\n",
    "embedding_encoding = \"cl100k_base\"  # this the tokenizer for text-embedding-ada-002\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191\n",
    "\n",
    "# get encoding\n",
    "encoding = tiktoken.get_encoding(embedding_encoding)\n",
    "\n",
    "def generate_embeddings(embeddings_file, queries):\n",
    "    # generate embeddings for new queries\n",
    "    embeddings = []\n",
    "    for query in queries:\n",
    "        embeddings.append(get_embedding(query, model=embedding_model))\n",
    "\n",
    "    # save the updated embeddings to the file\n",
    "    with open(embeddings_file, 'wb') as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "\n",
    "    # verify embeddings loaded\n",
    "    assert(len(embeddings) == len(queries))\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "from qdrant_client.http import models\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    host=\"localhost\",\n",
    "    prefer_grpc=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qdrant_collection(collection_name, embeddings, queries, functions):\n",
    "    client.delete_collection(collection_name=collection_name)\n",
    "    client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config={\n",
    "            'query': models.VectorParams(size=1536, distance=models.Distance.COSINE)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    payload = []\n",
    "    for i in range(len(functions)):\n",
    "        payload.append(\n",
    "            {\n",
    "                \"function\": functions[i]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    client.upsert(\n",
    "        collection_name = collection_name,\n",
    "        points = models.Batch(\n",
    "            ids=range(len(queries)),\n",
    "            vectors={\n",
    "                \"query\": embeddings\n",
    "            },\n",
    "            payloads=payload\n",
    "        )\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        collections = client.get_collections()\n",
    "        print(\"Qdrant connection established.\")\n",
    "    except Exception as e:\n",
    "        print(\"Qdrant not connected.\")\n",
    "\n",
    "    # check collection size\n",
    "    print(f\"Collection size for {collection_name}: {client.count(collection_name=collection_name)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate collections to qdrant\n",
    "\n",
    "embeddings_tradesweep = generate_embeddings(\"./embeddings_tradesweep.pkl\", queries)\n",
    "generate_qdrant_collection(\"TradeSweep\", embeddings_tradesweep, queries, functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search data\n",
    "import openai\n",
    "openai.api_key = \"<YOUR_API_KEY_HERE>\"\n",
    "\n",
    "def query_qdrant(query, collection_name='prompt-embeddings', vector_name='query', top_k=3):\n",
    "    # creates embedding vector from user query\n",
    "    embedded_query = openai.embeddings.create(input=query, model=embedding_model).data[0].embedding\n",
    "\n",
    "    # get results\n",
    "    query_results = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=(\n",
    "            vector_name, embedded_query\n",
    "        ),\n",
    "        limit=top_k,\n",
    "    )\n",
    "\n",
    "    return query_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform search\n",
    "query_results = query_qdrant(query=\"Clean dates to have yyyy-mm-dd format.\", top_k=3)\n",
    "\n",
    "# display results\n",
    "for i, entry in enumerate(query_results):\n",
    "    print(f\"Function {i}:\\n\\t{entry.payload['function']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
